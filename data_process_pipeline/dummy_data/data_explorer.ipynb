{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab525c74-b119-4f78-b25b-9b3e6946e832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.24.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2023.4.0)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.31.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.31.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.30.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is still looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading huggingface_hub-0.29.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.4-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fsspec[http]<=2025.3.0,>=2023.1.0 (from datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.4.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.0 (from huggingface-hub>=0.24.0->datasets)\n",
      "  Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2022.12.7)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m192.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.31.1-py3-none-any.whl (484 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.3/484.3 kB\u001b[0m \u001b[31m127.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m128.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m133.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m181.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.3/287.3 kB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.8/219.8 kB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.6/206.6 kB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.9/333.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, xxhash, tzdata, tqdm, requests, pyarrow, propcache, multidict, hf-xet, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.6.0 dill-0.3.8 frozenlist-1.6.0 fsspec-2025.3.0 hf-xet-1.1.0 huggingface-hub-0.31.1 multidict-6.4.3 multiprocess-0.70.16 pandas-2.2.3 propcache-0.3.1 pyarrow-20.0.0 pytz-2025.2 requests-2.32.3 tqdm-4.67.1 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdc5312e-5cfd-4bcd-88ec-c07a704d1352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available splits: dict_keys(['tiktok', 'reddit'])\n",
      "\n",
      "First row of TikTok data:\n",
      "{'cultural group': 'American', 'context': 'in public', 'goal': None, 'relation': None, 'actor': 'people', 'actor_behavior': 'dress casually, often in comfortable clothing, with a preference for sweatpants and following dress codes', 'recipient': None, 'recipient_behavior': None, 'other_descriptions': None, 'topic': 'Dress Codes', 'agreement': 0.9, 'num_support_bin': '[1060, 1070)', 'time_range': \"{2021: '[180, 190)', 2022: '[600, 610)', 2023: '[270, 280)'}\", 'eval_whole_desc': 'In public settings within American culture, it is common for people to dress casually, often opting for comfortable clothing such as sweatpants while still adhering to dress codes. This relaxed approach to attire is widely regarded as the norm by a significant portion of the sampled population. It reflects a preference for comfort and practicality in daily dress, showcasing a relaxed and informal attitude towards clothing choices in various public settings.', 'eval_scenario': 'Travel Advising', 'eval_persona': 'A business professional from a formal corporate background, planning a first-time trip to the United States for a business conference, eager to blend in and avoid any potential faux pas', 'eval_question': \"I'm gearing up for a big conference in the States and I'm a bit worried about what to wear. I come from a formal work environment and I don't want to stand out in a negative way. Can you give me some tips on what kind of attire would be appropriate for a business setting over there? Should I be concerned about anything specific?\"}\n",
      "\n",
      "First row of Reddit data:\n",
      "{'cultural group': 'Americans', 'context': 'restaurant and service industry settings', 'goal': 'show appreciation and improve service quality', 'relation': 'service provider-client', 'actor': 'servers and customers', 'actor_behavior': 'engage in tipping culture with varying expectations and practices, including tipping out additional service staff and building rapport', 'recipient': 'servers and customers', 'recipient_behavior': 'provide and respond to service', 'other_descriptions': 'servers are paid low wages and rely on tips for income; tipping is influenced by service quality and meal price', 'topic': 'Social Norms and Etiquette', 'agreement': 0.7, 'num_support_bin': '[250, 260)', 'time_range': \"{2012: '[0, 10)', 2013: '[0, 10)', 2014: '[0, 10)', 2015: '[0, 10)', 2016: '[10, 20)', 2017: '[0, 10)', 2018: '[0, 10)', 2019: '[10, 20)', 2020: '[10, 20)', 2021: '[30, 40)', 2022: '[140, 150)'}\", 'eval_whole_desc': 'In restaurant and service industry settings within American culture, both servers and customers participate in a tipping culture with diverse expectations and practices. This includes not only tipping the primary server but also additional service staff, aiming to build rapport and show appreciation while potentially improving service quality. Servers in these settings often rely on tips due to low wages, and tipping behavior is influenced by the quality of service provided and the total cost of the meal. This tipping culture is widely regarded as a common practice within the sampled population, reflecting the prevalent nature of this behavior in American restaurant and service contexts.', 'eval_scenario': 'Travel Advising', 'eval_persona': \"A budget-conscious traveler from Europe planning their first trip to the United States, eager to navigate the local dining scene and curious about how to best show appreciation for the excellent service they've heard about.\", 'eval_question': \"I've heard so much about the incredible service here in the US, and I'm really excited to try out the local food. However, I'm a bit confused about how tipping works. I want to make sure I'm treating the staff well, but I'm also trying to keep my costs down. Could you give me some advice on what to expect and how to navigate this new tipping culture without breaking the bank?\"}\n",
      "\n",
      "TikTok subset shape: (1000, 17)\n",
      "Reddit subset shape: (1000, 17)\n",
      "\n",
      "TikTok columns: ['cultural group', 'context', 'goal', 'relation', 'actor', 'actor_behavior', 'recipient', 'recipient_behavior', 'other_descriptions', 'topic', 'agreement', 'num_support_bin', 'time_range', 'eval_whole_desc', 'eval_scenario', 'eval_persona', 'eval_question']\n",
      "Reddit columns: ['cultural group', 'context', 'goal', 'relation', 'actor', 'actor_behavior', 'recipient', 'recipient_behavior', 'other_descriptions', 'topic', 'agreement', 'num_support_bin', 'time_range', 'eval_whole_desc', 'eval_scenario', 'eval_persona', 'eval_question']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"SALT-NLP/CultureBank\")\n",
    "\n",
    "# Let's examine both splits\n",
    "print(\"Available splits:\", dataset.keys())\n",
    "\n",
    "# Let's look at the first row of each split\n",
    "print(\"\\nFirst row of TikTok data:\")\n",
    "print(dataset['tiktok'][0])\n",
    "print(\"\\nFirst row of Reddit data:\")\n",
    "print(dataset['reddit'][0])\n",
    "\n",
    "# Create subsets of 1000 rows from each split\n",
    "tiktok_subset = dataset['tiktok'].select(range(1000))\n",
    "reddit_subset = dataset['reddit'].select(range(1000))\n",
    "\n",
    "# Convert to pandas DataFrames\n",
    "tiktok_df = pd.DataFrame(tiktok_subset)\n",
    "reddit_df = pd.DataFrame(reddit_subset)\n",
    "\n",
    "# Save the subsets\n",
    "tiktok_df.to_csv('tiktok_subset.csv', index=False)\n",
    "reddit_df.to_csv('reddit_subset.csv', index=False)\n",
    "\n",
    "# Print some basic information\n",
    "print(\"\\nTikTok subset shape:\", tiktok_df.shape)\n",
    "print(\"Reddit subset shape:\", reddit_df.shape)\n",
    "print(\"\\nTikTok columns:\", tiktok_df.columns.tolist())\n",
    "print(\"Reddit columns:\", reddit_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c65cc35a-31f1-4196-a29e-2fcc6eabecce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TIKTOK DATASET INFO\n",
      "==================================================\n",
      "Shape: (1000, 17)\n",
      "\n",
      "Columns:\n",
      "- cultural group\n",
      "- context\n",
      "- goal\n",
      "- relation\n",
      "- actor\n",
      "- actor_behavior\n",
      "- recipient\n",
      "- recipient_behavior\n",
      "- other_descriptions\n",
      "- topic\n",
      "- agreement\n",
      "- num_support_bin\n",
      "- time_range\n",
      "- eval_whole_desc\n",
      "- eval_scenario\n",
      "- eval_persona\n",
      "- eval_question\n",
      "\n",
      "First row sample:\n",
      "cultural group: American\n",
      "context: in public\n",
      "goal: None\n",
      "relation: None\n",
      "actor: people\n",
      "actor_behavior: dress casually, often in comfortable clothing, with a preference for sweatpants and following dress ...\n",
      "recipient: None\n",
      "recipient_behavior: None\n",
      "other_descriptions: None\n",
      "topic: Dress Codes\n",
      "agreement: 0.9\n",
      "num_support_bin: [1060, 1070)\n",
      "time_range: {2021: '[180, 190)', 2022: '[600, 610)', 2023: '[270, 280)'}\n",
      "eval_whole_desc: In public settings within American culture, it is common for people to dress casually, often opting ...\n",
      "eval_scenario: Travel Advising\n",
      "eval_persona: A business professional from a formal corporate background, planning a first-time trip to the United...\n",
      "eval_question: I'm gearing up for a big conference in the States and I'm a bit worried about what to wear. I come f...\n",
      "\n",
      "==================================================\n",
      "REDDIT DATASET INFO\n",
      "==================================================\n",
      "Shape: (1000, 17)\n",
      "\n",
      "Columns:\n",
      "- cultural group\n",
      "- context\n",
      "- goal\n",
      "- relation\n",
      "- actor\n",
      "- actor_behavior\n",
      "- recipient\n",
      "- recipient_behavior\n",
      "- other_descriptions\n",
      "- topic\n",
      "- agreement\n",
      "- num_support_bin\n",
      "- time_range\n",
      "- eval_whole_desc\n",
      "- eval_scenario\n",
      "- eval_persona\n",
      "- eval_question\n",
      "\n",
      "First row sample:\n",
      "cultural group: Americans\n",
      "context: restaurant and service industry settings\n",
      "goal: show appreciation and improve service quality\n",
      "relation: service provider-client\n",
      "actor: servers and customers\n",
      "actor_behavior: engage in tipping culture with varying expectations and practices, including tipping out additional ...\n",
      "recipient: servers and customers\n",
      "recipient_behavior: provide and respond to service\n",
      "other_descriptions: servers are paid low wages and rely on tips for income; tipping is influenced by service quality and...\n",
      "topic: Social Norms and Etiquette\n",
      "agreement: 0.7\n",
      "num_support_bin: [250, 260)\n",
      "time_range: {2012: '[0, 10)', 2013: '[0, 10)', 2014: '[0, 10)', 2015: '[0, 10)', 2016: '[10, 20)', 2017: '[0, 10...\n",
      "eval_whole_desc: In restaurant and service industry settings within American culture, both servers and customers part...\n",
      "eval_scenario: Travel Advising\n",
      "eval_persona: A budget-conscious traveler from Europe planning their first trip to the United States, eager to nav...\n",
      "eval_question: I've heard so much about the incredible service here in the US, and I'm really excited to try out th...\n"
     ]
    }
   ],
   "source": [
    "# Function to display data info in a cleaner way\n",
    "def display_data_info(df, name):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{name} DATASET INFO\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"\\nColumns:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"- {col}\")\n",
    "    print(\"\\nFirst row sample:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"{col}: {df.iloc[0][col][:100]}...\" if isinstance(df.iloc[0][col], str) and len(str(df.iloc[0][col])) > 100 else f\"{col}: {df.iloc[0][col]}\")\n",
    "\n",
    "# Display info for both datasets\n",
    "display_data_info(tiktok_df, \"TIKTOK\")\n",
    "display_data_info(reddit_df, \"REDDIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41874b27-870b-46ae-8cb2-30462078b9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame structure:\n",
      "   vid  comment_utc submission_title  \\\n",
      "0    0            0  Travel Advising   \n",
      "1    1            0  Travel Advising   \n",
      "2    2            0  Travel Advising   \n",
      "3    3            0  Travel Advising   \n",
      "4    4            0  Travel Advising   \n",
      "\n",
      "                                     comment_content  \n",
      "0  In public settings within American culture, it...  \n",
      "1  When Americans live or move to Europe, it is c...  \n",
      "2  In American restaurants, it is customary for c...  \n",
      "3  In the United States, tipping is a deeply ingr...  \n",
      "4  In American homes and some public settings, it...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read your TikTok data\n",
    "tiktok_df = pd.read_csv('tiktok_subset.csv')\n",
    "\n",
    "# Create a new DataFrame with the expected structure\n",
    "new_df = pd.DataFrame({\n",
    "    'vid': range(len(tiktok_df)),  # Create sequential IDs\n",
    "    'comment_utc': [0] * len(tiktok_df),  # Add dummy timestamp\n",
    "    'submission_title': tiktok_df['eval_scenario'],  # Map eval_scenario to submission_title\n",
    "    'comment_content': tiktok_df['eval_whole_desc']  # Map eval_whole_desc to comment_content\n",
    "})\n",
    "\n",
    "# Save the new DataFrame\n",
    "new_df.to_csv('tiktok_formatted.csv', index=False)\n",
    "\n",
    "print(\"New DataFrame structure:\")\n",
    "print(new_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
