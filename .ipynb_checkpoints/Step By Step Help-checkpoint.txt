#Head to the workBench 
#https://console.cloud.google.com/vertex-ai/workbench

# Select the CultureBank Instance and click on the Start on top nav 
# Once Started, click on the JupyterLab button in front of the instance
# Open a terminal where you can run git commands (directly connect to our git hub repositories, or run programs, install dependencies, etc)


# Helpful commands:
# cd .. to go back to the previous directory in the terminal if needed
# ls to list the files in the current directory
# pwd to print the current working directory
# clear to clear the terminal (ctrl + l also works)
# You can click on folder icon on the left to navigate to the folder and see the files/folders from left panel


# Always first ensure 

# In a termainal, Ensure you're in CultureBank directory . Should see something like (base) jupyter@culture-bank-instace:~/CultureBank$ on terminal. You can navigate to folder if needed,
cd CultureBank
# cd .. to go back to the previous directory in the terminal if needed

# IGNORE THIS, they're already installed in this environment
###################################################################
# install dependencies pip install -r requirements.txt
# pip install -r requirements.txt

# create conda environment and activate it
# conda create -n culturebank 

# activate the environment / Conda enviornment is already created so just need to activate it
# conda activate culturebank


# I have already added the OpenAI API key to the environment variable - but leaving this here for reference
# Add OpenAI API key to the environment variable
# export OPENAI_API_KEY="your_openai_api_key_goes_here" # Replace with your actual OpenAI API key
###################################################################

# Run the step 0 of pipeline to test if the pipeline is working with command below: (You need to be in CultureBank directory to run this command)
# If CultureBank/data_process_pipeline/results folder is not empty, running the programs will prompt you to overwrite the files Y/Yes, Type Capital Y or YES to overwrite the files
PYTHONPATH=$PYTHONPATH:$(pwd) python data_process_pipeline/main.py -i 0 -c data_process_pipeline/configs/config_dummy_data_vanilla_mistral.yaml

# If you want to run the pipeline step by step, you can run the command below: (0 is for step 0, 1 is for step 1, etc)
# PYTHONPATH=$PYTHONPATH:$(pwd) python data_process_pipeline/main.py -i 0 -c data_process_pipeline/configs/config_dummy_data_vanilla_mistral.yaml

# WE NEED TO SET UP GPUs TO RUN THE ENTIRE PIPELINE (current environement is CPU only, I will add GPUs soon)
# If you want to run the entire 0,1,3,4,5,6,7,8 steps, you can run the command below:
PYTHONPATH=$PYTHONPATH:$(pwd) python data_process_pipeline/main.py -i 0,1,3,4,5,6,7,8 -c data_process_pipeline/configs/config_dummy_data_vanilla_mistral.yaml

